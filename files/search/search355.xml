Computer Vision (Practical):@0.626365:0.948923:0.818571:0.948923:0.818571:0.935211:0.626365:0.935211:0.009968:0.009436:0.013865:0.009469:0.009114:0.005459:0.008422:0.005604:0.004412:0.010000:0.003897:0.006828:0.003897:0.009436:0.009114:0.004412:0.004863:0.009018:0.005604:0.008196:0.007440:0.005459:0.003897:0.007440:0.008196:0.003897:0.004863
353:@0.853958:0.949910:0.879997:0.949910:0.879997:0.936198:0.853958:0.936198:0.008680:0.008680:0.008680
 :@0.095158:0.070488:0.099791:0.070488:0.099791:0.056090:0.095158:0.056090:0.004633
•:@0.087381:0.068788:0.095159:0.068788:0.095159:0.052908:0.087381:0.052908:0.007778
If the value in the feature map is positive, it stays the same.:@0.105639:0.070488:0.544543:0.070488:0.544543:0.056090:0.105639:0.056090:0.004498:0.005292:0.004633:0.005732:0.009570:0.008843:0.004633:0.008099:0.008606:0.004092:0.009570:0.008843:0.004633:0.004092:0.009570:0.004633:0.005732:0.009570:0.008843:0.004633:0.005292:0.008843:0.008606:0.005732:0.009570:0.005884:0.008843:0.004633:0.014558:0.008606:0.009942:0.004633:0.004092:0.007169:0.004633:0.009942:0.009908:0.007169:0.004092:0.005732:0.004092:0.008099:0.008843:0.003669:0.004633:0.004092:0.005732:0.004633:0.007169:0.005732:0.008606:0.008184:0.007169:0.004633:0.005732:0.009570:0.008843:0.004633:0.007169:0.008606:0.014558:0.008843:0.003669
 :@0.095158:0.092506:0.099791:0.092506:0.099791:0.078109:0.095158:0.078109:0.004633
•:@0.087381:0.090806:0.095159:0.090806:0.095159:0.074926:0.087381:0.074926:0.007778
If the value is negative, it is set to zero.:@0.105639:0.092506:0.393569:0.092506:0.393569:0.078109:0.105639:0.078109:0.004498:0.005292:0.004633:0.005732:0.009570:0.008843:0.004633:0.008099:0.008606:0.004092:0.009570:0.008843:0.004633:0.004092:0.007169:0.004633:0.009570:0.008843:0.009959:0.008606:0.005732:0.004092:0.008099:0.008843:0.003669:0.004633:0.004092:0.005732:0.004633:0.004092:0.007169:0.004633:0.007169:0.008843:0.005732:0.004633:0.005732:0.009908:0.004633:0.007643:0.008843:0.005884:0.009908:0.003669
This operation allows the network to focus more on the significant features of the input image  which is particularly :@0.087381:0.114524:0.932605:0.114524:0.932605:0.100127:0.087381:0.100127:0.008860:0.009570:0.004092:0.007169:0.003806:0.009908:0.009942:0.008843:0.005884:0.008606:0.005732:0.004092:0.009908:0.009557:0.003801:0.008606:0.004092:0.004092:0.009908:0.012225:0.007169:0.003801:0.005732:0.009570:0.008843:0.003796:0.009570:0.008843:0.005732:0.012225:0.009908:0.005884:0.008403:0.003786:0.005732:0.009908:0.003798:0.005292:0.009908:0.007812:0.009570:0.007169:0.003801:0.014558:0.009908:0.005884:0.008843:0.003799:0.009908:0.009570:0.003798:0.005732:0.009570:0.008843:0.003796:0.007169:0.004092:0.009959:0.009570:0.004092:0.004692:0.004692:0.007812:0.008606:0.009570:0.005732:0.003789:0.005292:0.008843:0.008606:0.005732:0.009570:0.005884:0.008843:0.007169:0.003791:0.009908:0.005292:0.003799:0.005732:0.009570:0.008843:0.003796:0.004092:0.009570:0.009942:0.009570:0.005732:0.003798:0.004092:0.014558:0.008606:0.009959:0.008843:0.003803:0.003801:0.012225:0.009570:0.004092:0.007812:0.009570:0.003794:0.004092:0.007169:0.003810:0.009942:0.008606:0.005884:0.005732:0.004092:0.007812:0.009570:0.004092:0.008606:0.005884:0.004092:0.008184:0.004633
useful in tasks like :@0.087381:0.133042:0.226620:0.133042:0.226620:0.118645:0.087381:0.118645:0.009570:0.007169:0.008843:0.005292:0.009570:0.004092:0.004633:0.004092:0.009570:0.004633:0.005732:0.008606:0.007169:0.008403:0.007169:0.004633:0.004092:0.004092:0.008403:0.008843:0.004633
image recognition:@0.226634:0.133219:0.372001:0.133219:0.372001:0.118759:0.226634:0.118759:0.004802:0.015488:0.009097:0.010466:0.009147:0.004667:0.006669:0.009147:0.008116:0.010331:0.010466:0.010229:0.004802:0.006577:0.004802:0.010331:0.010229
.:@0.372022:0.133042:0.375691:0.133042:0.375691:0.118645:0.372022:0.118645:0.003669
Mathematically, ReLU can be represented as::@0.087381:0.155060:0.419345:0.155060:0.419345:0.140663:0.087381:0.140663:0.015184:0.008606:0.005732:0.009570:0.008843:0.014558:0.008606:0.005732:0.004092:0.007812:0.008606:0.004092:0.004092:0.008184:0.003669:0.004633:0.009607:0.008843:0.007627:0.011616:0.004633:0.007812:0.008606:0.009570:0.004633:0.009942:0.008843:0.004633:0.005884:0.008843:0.009942:0.005884:0.008843:0.007169:0.008843:0.009570:0.005732:0.008843:0.009959:0.004633:0.008606:0.007169:0.003669
ReLU(x) = max(0, x):@0.087381:0.177255:0.245476:0.177255:0.245476:0.162795:0.087381:0.162795:0.010617:0.009147:0.008307:0.012225:0.006239:0.009333:0.006239:0.004667:0.011954:0.004667:0.015488:0.009097:0.009333:0.006239:0.009722:0.004582:0.004667:0.009333:0.006239
This means that if x is greater than 0, it remains unchanged. But if x is less than or equal to 0, it becomes 0.:@0.087381:0.199097:0.879852:0.199097:0.879852:0.184699:0.087381:0.184699:0.008860:0.009570:0.004092:0.007169:0.004633:0.014558:0.008843:0.008606:0.009570:0.007169:0.004633:0.005732:0.009570:0.008606:0.005732:0.004633:0.004092:0.005292:0.004633:0.007761:0.004633:0.004092:0.007169:0.004633:0.009959:0.005884:0.008843:0.008606:0.005732:0.008843:0.005884:0.004633:0.005732:0.009570:0.008606:0.009570:0.004633:0.009114:0.003669:0.004633:0.004092:0.005732:0.004633:0.005884:0.008843:0.014558:0.008606:0.004092:0.009570:0.007169:0.004633:0.009570:0.009570:0.007812:0.009570:0.008606:0.009570:0.009959:0.008843:0.009959:0.003669:0.004633:0.009688:0.009570:0.005732:0.004633:0.004092:0.005292:0.004633:0.007761:0.004633:0.004092:0.007169:0.004633:0.004092:0.008843:0.007169:0.007169:0.004633:0.005732:0.009570:0.008606:0.009570:0.004633:0.009908:0.005884:0.004633:0.008843:0.009959:0.009570:0.008606:0.004092:0.004633:0.005732:0.009908:0.004633:0.009114:0.003669:0.004633:0.004092:0.005732:0.004633:0.009942:0.008843:0.007812:0.009908:0.014558:0.008843:0.007169:0.004633:0.009114:0.003669
Let us see it through a graph::@0.087381:0.221115:0.305564:0.221115:0.305564:0.206718:0.087381:0.206718:0.007964:0.008843:0.005732:0.004633:0.009570:0.007169:0.004633:0.007169:0.008843:0.008843:0.004633:0.004092:0.005732:0.004633:0.005732:0.009570:0.005884:0.009908:0.009570:0.009959:0.009570:0.004633:0.008606:0.004633:0.009959:0.005884:0.008606:0.009942:0.009570:0.003669
2:@0.671768:0.351249:0.678712:0.351249:0.678712:0.340279:0.671768:0.340279:0.006944
4:@0.671768:0.328463:0.678712:0.328463:0.678712:0.317494:0.671768:0.317494:0.006944
6:@0.671768:0.305056:0.678712:0.305056:0.678712:0.294087:0.671768:0.294087:0.006944
8:@0.671768:0.282626:0.678712:0.282626:0.678712:0.271657:0.671768:0.271657:0.006944
10:@0.664927:0.259910:0.678815:0.259910:0.678815:0.248941:0.664927:0.248941:0.006944:0.006944
–10:@0.550995:0.380641:0.571324:0.380641:0.571324:0.369672:0.550995:0.369672:0.006441:0.006944:0.006944
–10 –8 –6 –4:@0.202525:0.359960:0.297378:0.359960:0.297378:0.348990:0.202525:0.348990:0.006441:0.006944:0.006944:0.009675:0.006441:0.006944:0.012586:0.006441:0.006944:0.012110:0.006441:0.006944
–2 0:@0.311987:0.359960:0.344889:0.359960:0.344889:0.348990:0.311987:0.348990:0.006441:0.006944:0.012573:0.006944
2:@0.358699:0.359960:0.365642:0.359960:0.365642:0.348990:0.358699:0.348990:0.006944
1:@0.322551:0.328997:0.329494:0.328997:0.329494:0.318028:0.322551:0.318028:0.006944
2:@0.322551:0.310133:0.329494:0.310133:0.329494:0.299163:0.322551:0.299163:0.006944
–4:@0.318531:0.422814:0.331916:0.422814:0.331916:0.411845:0.318531:0.411845:0.006441:0.006944
3:@0.322551:0.292463:0.329494:0.292463:0.329494:0.281494:0.322551:0.281494:0.006944
–3:@0.318531:0.403170:0.331916:0.403170:0.331916:0.392200:0.318531:0.392200:0.006441:0.006944
4:@0.322551:0.272345:0.329494:0.272345:0.329494:0.261376:0.322551:0.261376:0.006944
–2:@0.318531:0.384286:0.331916:0.384286:0.331916:0.373316:0.318531:0.373316:0.006441:0.006944
5:@0.322551:0.253797:0.329494:0.253797:0.329494:0.242828:0.322551:0.242828:0.006944
–1:@0.318531:0.365866:0.331916:0.365866:0.331916:0.354897:0.318531:0.354897:0.006441:0.006944
4:@0.383562:0.359980:0.390505:0.359980:0.390505:0.349010:0.383562:0.349010:0.006944
6:@0.411130:0.359980:0.418074:0.359980:0.418074:0.349010:0.411130:0.349010:0.006944
8:@0.438145:0.359980:0.445088:0.359980:0.445088:0.349010:0.438145:0.349010:0.006944
10:@0.459491:0.359980:0.473378:0.359980:0.473378:0.349010:0.459491:0.349010:0.006944:0.006944
–5:@0.615304:0.380661:0.628689:0.380661:0.628689:0.369692:0.615304:0.369692:0.006441:0.006944
5:@0.741720:0.380661:0.748663:0.380661:0.748663:0.369692:0.741720:0.369692:0.006944
Output = Max(zero, Input):@0.594915:0.420013:0.781372:0.420013:0.781372:0.406302:0.594915:0.406302:0.012142:0.009114:0.005459:0.009469:0.009114:0.005459:0.004412:0.011014:0.004412:0.014461:0.008196:0.007391:0.004863:0.007279:0.008422:0.005604:0.009436:0.003494:0.004412:0.004283:0.009114:0.009469:0.009114:0.005459:0.004863
10:@0.795710:0.380645:0.809597:0.380645:0.809597:0.369676:0.795710:0.369676:0.006944:0.006944
 :@0.087381:0.457528:0.091352:0.457528:0.091352:0.445187:0.087381:0.445187:0.003971
Graph Before ReLU :@0.280613:0.457528:0.405450:0.457528:0.405450:0.445187:0.280613:0.445187:0.009942:0.005043:0.007377:0.008522:0.008203:0.003971:0.008304:0.007580:0.004536:0.008493:0.005043:0.007580:0.003971:0.008228:0.007580:0.006538:0.009957:0.003971
Graph After ReLU:@0.626207:0.457528:0.736955:0.457528:0.736955:0.445187:0.626207:0.445187:0.009942:0.005043:0.007377:0.008522:0.008203:0.003971:0.009348:0.004536:0.004913:0.007580:0.005043:0.003971:0.008225:0.007580:0.006538:0.009957
When  the :@0.087381:0.483696:0.167262:0.483696:0.167262:0.469298:0.087381:0.469298:0.015792:0.009570:0.008843:0.009570:0.004633:0.002695:0.005732:0.009570:0.008843:0.004633
feature map values:@0.169954:0.483872:0.326763:0.483872:0.326763:0.469412:0.169954:0.469412:0.006476:0.009147:0.009097:0.006577:0.010229:0.006665:0.009147:0.007389:0.015488:0.009097:0.010483:0.007389:0.008909:0.009097:0.004802:0.010229:0.009147:0.007440
  (linear  graph)  are  passed  through  the  ReLU  layer,  all  the  negative  values  are :@0.326762:0.483696:0.932604:0.483696:0.932604:0.469298:0.326762:0.469298:0.004633:0.002697:0.005106:0.004092:0.004092:0.009570:0.008843:0.008606:0.005884:0.004633:0.002688:0.009959:0.005884:0.008606:0.009942:0.009570:0.005106:0.004633:0.002678:0.008606:0.005884:0.008843:0.004633:0.002687:0.009942:0.008606:0.007169:0.007169:0.008843:0.009959:0.004633:0.002699:0.005732:0.009570:0.005884:0.009908:0.009570:0.009959:0.009570:0.004633:0.002682:0.005732:0.009570:0.008843:0.004633:0.002694:0.009617:0.008843:0.007627:0.011616:0.004633:0.002697:0.004092:0.008606:0.008184:0.008843:0.005884:0.003669:0.004633:0.002685:0.008606:0.004092:0.004092:0.004633:0.002700:0.005732:0.009570:0.008843:0.004633:0.002694:0.009570:0.008843:0.009959:0.008606:0.005732:0.004092:0.008099:0.008843:0.004633:0.002688:0.008099:0.008606:0.004092:0.009570:0.008843:0.007169:0.004633:0.002700:0.008606:0.005884:0.008843:0.004633
converted to zero. The result is a graph that :@0.087381:0.502214:0.410897:0.502214:0.410897:0.487817:0.087381:0.487817:0.007812:0.009908:0.009570:0.008099:0.008843:0.005884:0.005732:0.008843:0.009959:0.003816:0.005732:0.009908:0.003830:0.007643:0.008843:0.005884:0.009908:0.003669:0.003823:0.008860:0.009570:0.008843:0.003830:0.005884:0.008843:0.007169:0.009570:0.004092:0.005732:0.003831:0.004092:0.007169:0.003840:0.008606:0.003830:0.009959:0.005884:0.008606:0.009942:0.009570:0.003816:0.005732:0.009570:0.008606:0.005732:0.004633
starts at zero:@0.410088:0.502390:0.512072:0.502390:0.512072:0.487931:0.410088:0.487931:0.007440:0.006577:0.009097:0.007220:0.006577:0.007440:0.003855:0.009097:0.006577:0.003865:0.008099:0.009147:0.006662:0.010331
 for negative inputs and then follows a straight line when :@0.512083:0.502214:0.932604:0.502214:0.932604:0.487817:0.512083:0.487817:0.003833:0.005292:0.009908:0.005884:0.003825:0.009570:0.008843:0.009959:0.008606:0.005732:0.004092:0.008099:0.008843:0.003825:0.004092:0.009570:0.009942:0.009570:0.005732:0.007169:0.003835:0.008606:0.009570:0.009959:0.003825:0.005732:0.009570:0.008843:0.009570:0.003826:0.005292:0.009908:0.004092:0.004092:0.009908:0.012225:0.007169:0.003837:0.008606:0.003828:0.007169:0.005732:0.005884:0.008606:0.004092:0.009959:0.009570:0.005732:0.003825:0.004092:0.004092:0.009570:0.008843:0.003837:0.012225:0.009570:0.008843:0.009570:0.004633
the values become positive.:@0.087381:0.520733:0.293255:0.520733:0.293255:0.506335:0.087381:0.506335:0.005732:0.009570:0.008843:0.004633:0.008099:0.008606:0.004092:0.009570:0.008843:0.007169:0.004633:0.009942:0.008843:0.007812:0.009908:0.014558:0.008843:0.004633:0.009942:0.009908:0.007169:0.004092:0.005732:0.004092:0.008099:0.008843:0.003669
Essentially, the graph :@0.087381:0.542751:0.249111:0.542751:0.249111:0.528354:0.087381:0.528354:0.008556:0.007169:0.007169:0.008843:0.009570:0.005732:0.004092:0.008606:0.004092:0.004092:0.008184:0.003669:0.004614:0.005732:0.009570:0.008843:0.004604:0.009959:0.005884:0.008606:0.009942:0.009570:0.004633
\flattens\ :@0.249072:0.542927:0.330700:0.542927:0.330700:0.528467:0.249072:0.528467:0.008336:0.005639:0.005639:0.009097:0.006577:0.006521:0.009147:0.010229:0.007440:0.008336:0.004667
at the negative side (where the output is zero) and then increases linearly on the :@0.330676:0.542751:0.932599:0.542751:0.932599:0.528354:0.330676:0.528354:0.008606:0.005732:0.004602:0.005732:0.009570:0.008843:0.004606:0.009570:0.008843:0.009959:0.008606:0.005732:0.004092:0.008099:0.008843:0.004601:0.007169:0.004092:0.009959:0.008843:0.004614:0.005106:0.012225:0.009570:0.008843:0.005884:0.008843:0.004591:0.005732:0.009570:0.008843:0.004604:0.009908:0.009570:0.005732:0.009942:0.009570:0.005732:0.004599:0.004092:0.007169:0.004618:0.007643:0.008843:0.005884:0.009908:0.005106:0.004599:0.008606:0.009570:0.009959:0.004602:0.005732:0.009570:0.008843:0.009570:0.004604:0.004092:0.009570:0.007812:0.005884:0.008843:0.008606:0.007169:0.008843:0.007169:0.004609:0.004092:0.004092:0.009570:0.008843:0.008606:0.005884:0.004092:0.008184:0.004604:0.009908:0.009570:0.004608:0.005732:0.009570:0.008843:0.004633
positive side. This introduces :@0.087381:0.561269:0.304509:0.561269:0.304509:0.546872:0.087381:0.546872:0.009942:0.009908:0.007169:0.004092:0.005732:0.004092:0.008099:0.008843:0.004220:0.007169:0.004092:0.009959:0.008843:0.003669:0.004217:0.008860:0.009570:0.004092:0.007169:0.004220:0.004092:0.009570:0.005732:0.005884:0.009908:0.009959:0.009570:0.007812:0.008843:0.007169:0.004633
non-linearity:@0.304084:0.561445:0.407070:0.561445:0.407070:0.546986:0.304084:0.546986:0.010229:0.010331:0.010229:0.006831:0.004802:0.004802:0.010229:0.009147:0.009097:0.006812:0.004802:0.006577:0.009097
 into the network. This non-linearity helps the network to better model :@0.407077:0.561269:0.932590:0.561269:0.932590:0.546872:0.407077:0.546872:0.004215:0.004092:0.009570:0.005732:0.009908:0.004214:0.005732:0.009570:0.008843:0.004210:0.009570:0.008843:0.005732:0.012225:0.009908:0.005884:0.008403:0.003669:0.004195:0.008860:0.009570:0.004092:0.007169:0.004220:0.009570:0.009908:0.009570:0.006763:0.004092:0.004092:0.009570:0.008843:0.008606:0.005884:0.004092:0.005732:0.008184:0.004203:0.009570:0.008843:0.004092:0.009942:0.007169:0.004220:0.005732:0.009570:0.008843:0.004210:0.009570:0.008843:0.005732:0.012225:0.009908:0.005884:0.008403:0.004198:0.005732:0.009908:0.004212:0.009942:0.008843:0.005732:0.005732:0.008843:0.005884:0.004202:0.014558:0.009908:0.009959:0.008843:0.004092:0.004633
complex patterns by allowing it to :@0.087381:0.579788:0.352899:0.579788:0.352899:0.565391:0.087381:0.565391:0.007812:0.009908:0.014558:0.009942:0.004092:0.008843:0.007761:0.006079:0.009942:0.008606:0.005732:0.005732:0.008833:0.005884:0.009570:0.007169:0.006073:0.009942:0.008184:0.006070:0.008606:0.004092:0.004092:0.009908:0.012225:0.004092:0.009570:0.009959:0.006072:0.004092:0.005732:0.006075:0.005732:0.009908:0.004633
activate only the important features:@0.354339:0.579964:0.647043:0.579964:0.647043:0.565504:0.354339:0.565504:0.009097:0.008116:0.006577:0.004802:0.008916:0.009097:0.006515:0.009147:0.006121:0.010331:0.010229:0.004802:0.009097:0.006121:0.006577:0.010179:0.009147:0.006121:0.004802:0.015488:0.010483:0.010331:0.007223:0.006577:0.009097:0.010229:0.006577:0.006121:0.006476:0.009147:0.009097:0.006577:0.010229:0.006672:0.009147:0.007440
 and ignore less relevant information :@0.647057:0.579788:0.932598:0.579788:0.932598:0.565391:0.647057:0.565391:0.006075:0.008606:0.009570:0.009959:0.006068:0.004092:0.009959:0.009570:0.009908:0.005884:0.008843:0.006067:0.004092:0.008843:0.007169:0.007169:0.006089:0.005884:0.008843:0.004092:0.008843:0.008099:0.008606:0.009570:0.005732:0.006063:0.004092:0.009570:0.005292:0.009908:0.005884:0.014558:0.008606:0.005732:0.004092:0.009908:0.009570:0.004633
(like negative values).:@0.087381:0.598306:0.246081:0.598306:0.246081:0.583909:0.087381:0.583909:0.005106:0.004092:0.004092:0.008403:0.008843:0.004633:0.009570:0.008843:0.009959:0.008606:0.005732:0.004092:0.008099:0.008843:0.004633:0.008099:0.008606:0.004092:0.009570:0.008843:0.007169:0.005106:0.003669
ReLU:@0.490376:0.693505:0.527899:0.693505:0.527899:0.679179:0.490376:0.679179:0.009574:0.008798:0.007592:0.011559
Input Feature Map:@0.230479:0.635447:0.367843:0.635447:0.367843:0.621120:0.230479:0.621120:0.004476:0.009523:0.009893:0.009523:0.005704:0.004610:0.008211:0.008800:0.008564:0.005704:0.009523:0.005855:0.008800:0.004610:0.015109:0.008564:0.009893
Black = negative;:@0.157892:0.777453:0.278756:0.777453:0.278756:0.764662:0.157892:0.764662:0.009587:0.004248:0.008046:0.007179:0.008361:0.004128:0.010574:0.004128:0.009048:0.008091:0.009258:0.008046:0.005818:0.004248:0.007960:0.008091:0.004053
 white = positive values:@0.278756:0.777453:0.444116:0.777453:0.444116:0.764662:0.278756:0.764662:0.004128:0.011920:0.009004:0.004248:0.005761:0.008091:0.004128:0.010574:0.004128:0.009273:0.009138:0.006581:0.004248:0.005818:0.004248:0.007961:0.008091:0.004128:0.007879:0.008046:0.004248:0.009048:0.008091:0.006581
Rectified Feature Map:@0.635100:0.635447:0.797312:0.635447:0.797312:0.621120:0.635100:0.621120:0.009570:0.008800:0.007773:0.005704:0.004072:0.004669:0.004669:0.008800:0.009910:0.004610:0.008211:0.008800:0.008564:0.005704:0.009523:0.005855:0.008800:0.004610:0.015109:0.008564:0.009893
Only non-negative values:@0.567605:0.777029:0.746272:0.777029:0.746272:0.764239:0.567605:0.764239:0.011337:0.009048:0.004248:0.008046:0.004128:0.009048:0.009138:0.009048:0.006042:0.009048:0.008091:0.009258:0.008046:0.005818:0.004248:0.007960:0.008091:0.004128:0.007879:0.008046:0.004248:0.009048:0.008091:0.006581
In the resulting feature map after applying ReLU::@0.087381:0.808922:0.448880:0.808922:0.448880:0.794525:0.087381:0.794525:0.004498:0.009570:0.004633:0.005732:0.009570:0.008843:0.004633:0.005884:0.008843:0.007169:0.009570:0.004092:0.005732:0.004092:0.009570:0.009959:0.004633:0.005292:0.008843:0.008606:0.005732:0.009570:0.005884:0.008843:0.004633:0.014558:0.008606:0.009942:0.004633:0.008606:0.005292:0.005732:0.008843:0.005884:0.004633:0.008606:0.009942:0.009942:0.004092:0.008184:0.004092:0.009570:0.009959:0.004633:0.009570:0.008843:0.007627:0.011616:0.003669
When the ReLU activation function is applied, it eliminates all negative values, essentially flattening the regions :@0.087381:0.830940:0.932597:0.830940:0.932597:0.816543:0.087381:0.816543:0.015792:0.009570:0.008843:0.009570:0.005820:0.005732:0.009570:0.008843:0.005818:0.009617:0.008843:0.007627:0.011616:0.005823:0.008606:0.007812:0.005732:0.004092:0.008099:0.008606:0.005732:0.004092:0.009908:0.009570:0.005813:0.005292:0.009570:0.009570:0.007812:0.005732:0.004092:0.009908:0.009570:0.005816:0.004092:0.007169:0.005830:0.008606:0.009942:0.009942:0.004092:0.004092:0.008843:0.009959:0.003669:0.005815:0.004092:0.005732:0.005823:0.008843:0.004092:0.004092:0.014558:0.004092:0.009570:0.008606:0.005732:0.008843:0.007169:0.005833:0.008606:0.004092:0.004092:0.005825:0.009570:0.008843:0.009959:0.008606:0.005732:0.004092:0.008099:0.008843:0.005813:0.008099:0.008606:0.004092:0.009570:0.008843:0.007169:0.003669:0.005822:0.008843:0.007169:0.007169:0.008843:0.009570:0.005732:0.004092:0.008606:0.004092:0.004092:0.008184:0.005832:0.004692:0.004692:0.008606:0.005732:0.005732:0.008843:0.009570:0.004092:0.009570:0.009959:0.005806:0.005732:0.009570:0.008843:0.005818:0.005884:0.008843:0.009959:0.004092:0.009908:0.009570:0.007169:0.004633
where there is no significant change or where the pixel values are below zero.:@0.087381:0.849459:0.663630:0.849459:0.663630:0.835061:0.087381:0.835061:0.012225:0.009570:0.008843:0.005884:0.008843:0.004633:0.005732:0.009570:0.008843:0.005884:0.008843:0.004633:0.004092:0.007169:0.004633:0.009570:0.009908:0.004633:0.007169:0.004092:0.009959:0.009570:0.004092:0.004692:0.004692:0.007812:0.008606:0.009570:0.005732:0.004633:0.007812:0.009570:0.008606:0.009570:0.009959:0.008843:0.004633:0.009908:0.005884:0.004633:0.012225:0.009570:0.008843:0.005884:0.008843:0.004633:0.005732:0.009570:0.008843:0.004633:0.009942:0.004092:0.007761:0.008843:0.004092:0.004633:0.008099:0.008606:0.004092:0.009570:0.008843:0.007169:0.004633:0.008606:0.005884:0.008843:0.004633:0.009942:0.008843:0.004092:0.009908:0.012225:0.004633:0.007643:0.008843:0.005884:0.009908:0.003669
As a result, :@0.087381:0.871477:0.173614:0.871477:0.173614:0.857080:0.087381:0.857080:0.010906:0.007169:0.004983:0.008606:0.004978:0.005884:0.008843:0.007169:0.009570:0.004092:0.005732:0.003669:0.004633
positive values:@0.173947:0.871653:0.291179:0.871653:0.291179:0.857193:0.173947:0.857193:0.010483:0.010331:0.007440:0.004802:0.006577:0.004802:0.009014:0.009147:0.005013:0.008907:0.009097:0.004802:0.010229:0.009147:0.007440
 are kept, and the :@0.291182:0.871477:0.427899:0.871477:0.427899:0.857080:0.291182:0.857080:0.004976:0.008606:0.005884:0.008843:0.004966:0.008403:0.008843:0.009942:0.005732:0.003669:0.004969:0.008606:0.009570:0.009959:0.004969:0.005732:0.009570:0.008843:0.004633
transitions between dark and light areas:@0.428238:0.871653:0.749538:0.871653:0.749538:0.857193:0.428238:0.857193:0.006577:0.006729:0.009097:0.010229:0.007440:0.004802:0.006577:0.004802:0.010331:0.010245:0.007440:0.005012:0.010483:0.009147:0.006577:0.013405:0.009147:0.009147:0.010229:0.005012:0.010466:0.009097:0.006729:0.009452:0.005022:0.009097:0.010229:0.010466:0.005022:0.004802:0.004802:0.010466:0.010179:0.006577:0.005022:0.009097:0.006663:0.009147:0.009097:0.007440
 become more :@0.749530:0.871477:0.863214:0.871477:0.863214:0.857080:0.749530:0.857080:0.004976:0.009942:0.008843:0.007812:0.009908:0.014558:0.008843:0.004976:0.014558:0.009908:0.005884:0.008843:0.004633
defined:@0.863556:0.871653:0.924290:0.871653:0.924290:0.857193:0.863556:0.857193:0.010466:0.009147:0.005639:0.005639:0.010229:0.009147:0.010466
, :@0.924295:0.871477:0.932597:0.871477:0.932597:0.857080:0.924295:0.857080:0.003669:0.004633
enhancing the edges and features in the feature map:@0.087381:0.890171:0.507714:0.890171:0.507714:0.875712:0.087381:0.875712:0.009147:0.010229:0.010179:0.009097:0.010229:0.008116:0.004802:0.010229:0.010466:0.004667:0.006577:0.010179:0.009147:0.004667:0.009147:0.010466:0.010466:0.009147:0.007440:0.004667:0.009097:0.010229:0.010466:0.004667:0.006476:0.009147:0.009097:0.006577:0.010229:0.006682:0.009147:0.007440:0.004667:0.004802:0.010229:0.004667:0.006577:0.010179:0.009147:0.004667:0.006476:0.009147:0.009097:0.006577:0.010229:0.006670:0.009147:0.004667:0.015488:0.009097:0.010483
.:@0.507717:0.889995:0.511386:0.889995:0.511386:0.875598:0.507717:0.875598:0.003669