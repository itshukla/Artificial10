Evaluating Models:@0.688403:0.948923:0.818564:0.948923:0.818564:0.935211:0.688403:0.935211:0.008148:0.007713:0.008196:0.003897:0.009114:0.008196:0.005459:0.003897:0.009114:0.009485:0.004412:0.014461:0.009436:0.009485:0.008422:0.003897:0.006828
247:@0.853958:0.949910:0.879997:0.949910:0.879997:0.936198:0.853958:0.936198:0.008680:0.008680:0.008680
 :@0.087395:0.068868:0.091586:0.068868:0.091586:0.055842:0.087395:0.055842:0.004192
7.  Which of the following statements is true about F1 Score?:@0.116185:0.068868:0.526705:0.068868:0.526705:0.055842:0.116185:0.055842:0.008246:0.003320:0.004192:0.005370:0.014288:0.008659:0.003702:0.007068:0.008659:0.004192:0.008965:0.004788:0.004192:0.005186:0.008659:0.008001:0.004192:0.004788:0.008965:0.003702:0.003702:0.008965:0.011060:0.003702:0.008659:0.009010:0.004192:0.006486:0.005186:0.007787:0.005186:0.008001:0.013171:0.008001:0.008659:0.005186:0.006486:0.004192:0.003702:0.006486:0.004192:0.005186:0.005324:0.008659:0.008001:0.004192:0.007787:0.008995:0.008965:0.008659:0.005186:0.004192:0.007465:0.008246:0.004192:0.008123:0.007068:0.008965:0.005324:0.008001:0.006853
a.  F1 score is the average of precision and recall. :@0.135704:0.090886:0.471814:0.090886:0.471814:0.077860:0.135704:0.077860:0.007787:0.003320:0.004192:0.007251:0.007465:0.008246:0.004192:0.006486:0.007068:0.008965:0.005324:0.008001:0.004192:0.003702:0.006486:0.004192:0.005186:0.008659:0.008001:0.004192:0.007787:0.007328:0.008001:0.005324:0.007787:0.009010:0.008001:0.004192:0.008965:0.004788:0.004192:0.008995:0.005324:0.008001:0.007068:0.003702:0.006486:0.003702:0.008965:0.008659:0.004192:0.007787:0.008659:0.009010:0.004192:0.005324:0.008001:0.007068:0.007787:0.003702:0.003702:0.003320:0.004192
b.  F1 score only considers false negatives. :@0.135704:0.115528:0.425630:0.115528:0.425630:0.102502:0.135704:0.102502:0.008995:0.003320:0.004192:0.006043:0.007465:0.008246:0.004192:0.006486:0.007068:0.008965:0.005324:0.008001:0.004192:0.008965:0.008659:0.003702:0.007404:0.004192:0.007068:0.008965:0.008659:0.006486:0.003702:0.009010:0.008001:0.005324:0.006486:0.004192:0.004788:0.007787:0.003702:0.006486:0.008001:0.004192:0.008659:0.008001:0.009010:0.007787:0.005186:0.003702:0.007328:0.008001:0.006486:0.003320:0.004192
c.  F1 score is the sum of precision and recall. :@0.135704:0.140171:0.446894:0.140171:0.446894:0.127145:0.135704:0.127145:0.007068:0.003320:0.004192:0.007970:0.007465:0.008246:0.004192:0.006486:0.007068:0.008965:0.005324:0.008001:0.004192:0.003702:0.006486:0.004192:0.005186:0.008659:0.008001:0.004192:0.006486:0.008659:0.013171:0.004192:0.008965:0.004788:0.004192:0.008995:0.005324:0.008001:0.007068:0.003702:0.006486:0.003702:0.008965:0.008659:0.004192:0.007787:0.008659:0.009010:0.004192:0.005324:0.008001:0.007068:0.007787:0.003702:0.003702:0.003320:0.004192
d.  F1 score is always equal to the accuracy of the model. :@0.135704:0.164814:0.523414:0.164814:0.523414:0.151788:0.135704:0.151788:0.009010:0.003320:0.004192:0.006027:0.007465:0.008246:0.004192:0.006486:0.007068:0.008965:0.005324:0.008001:0.004192:0.003702:0.006486:0.004192:0.007787:0.003702:0.011060:0.007787:0.007404:0.006486:0.004192:0.008001:0.009010:0.008659:0.007787:0.003702:0.004192:0.005186:0.008965:0.004192:0.005186:0.008659:0.008001:0.004192:0.007787:0.007068:0.007068:0.008659:0.005324:0.007787:0.007068:0.007404:0.004192:0.008965:0.004788:0.004192:0.005186:0.008659:0.008001:0.004192:0.013171:0.008965:0.009010:0.008001:0.003702:0.003320:0.004192
 :@0.087395:0.191276:0.091586:0.191276:0.091586:0.178250:0.087395:0.178250:0.004192
8.  What does  the recall metric measure in a classification  problem?:@0.116185:0.191276:0.578350:0.191276:0.578350:0.178250:0.116185:0.178250:0.008246:0.003320:0.004192:0.005370:0.014288:0.008659:0.007787:0.005186:0.004192:0.009010:0.008965:0.008001:0.006486:0.004192:0.004192:0.005186:0.008659:0.008001:0.004192:0.005324:0.008001:0.007068:0.007787:0.003702:0.003702:0.004192:0.013171:0.008001:0.005186:0.005324:0.003702:0.007068:0.004192:0.013171:0.008001:0.007787:0.006486:0.008659:0.005324:0.008001:0.004192:0.003702:0.008659:0.004192:0.007787:0.004192:0.007068:0.003702:0.007787:0.006486:0.006486:0.003702:0.004788:0.003702:0.007068:0.007787:0.005186:0.003702:0.008965:0.008659:0.004192:0.004192:0.008995:0.005324:0.008965:0.008995:0.003702:0.008001:0.013171:0.006853
a.  The proportion of true positive instances out of all predicted positive instances :@0.135704:0.213294:0.692073:0.213294:0.692073:0.200269:0.135704:0.200269:0.007787:0.003320:0.004192:0.007251:0.008016:0.008659:0.008001:0.004192:0.008995:0.005324:0.008965:0.008995:0.008965:0.005324:0.005186:0.003702:0.008965:0.008659:0.004192:0.008965:0.004788:0.004192:0.005186:0.005324:0.008659:0.008001:0.004192:0.008995:0.008965:0.006486:0.003702:0.005186:0.003702:0.007328:0.008001:0.004192:0.003702:0.008659:0.006486:0.005186:0.007787:0.008659:0.007068:0.008001:0.006486:0.004192:0.008965:0.008659:0.005186:0.004192:0.008965:0.004788:0.004192:0.007787:0.003702:0.003702:0.004192:0.008995:0.005324:0.008001:0.009010:0.003702:0.007068:0.005186:0.008001:0.009010:0.004192:0.008995:0.008965:0.006486:0.003702:0.005186:0.003702:0.007328:0.008001:0.004192:0.003702:0.008659:0.006486:0.005186:0.007787:0.008659:0.007068:0.008001:0.006486:0.004192
b.  The proportion of actual positive instances that were correctly identified :@0.135704:0.236257:0.647266:0.236257:0.647266:0.223231:0.135704:0.223231:0.008995:0.003320:0.004192:0.006043:0.008016:0.008659:0.008001:0.004192:0.008995:0.005324:0.008965:0.008995:0.008965:0.005324:0.005186:0.003702:0.008965:0.008659:0.004192:0.008965:0.004788:0.004192:0.007787:0.007068:0.005186:0.008659:0.007787:0.003702:0.004192:0.008995:0.008965:0.006486:0.003702:0.005186:0.003702:0.007328:0.008001:0.004192:0.003702:0.008659:0.006486:0.005186:0.007787:0.008659:0.007068:0.008001:0.006486:0.004192:0.005186:0.008659:0.007787:0.005186:0.004192:0.011060:0.008001:0.005324:0.008001:0.004192:0.007068:0.008965:0.005324:0.005324:0.008001:0.007068:0.005186:0.003702:0.007404:0.004192:0.003702:0.009010:0.008001:0.008659:0.005186:0.003702:0.004788:0.003702:0.008001:0.009010:0.004192
c.  The overall accuracy of the model :@0.135704:0.259220:0.389496:0.259220:0.389496:0.246194:0.135704:0.246194:0.007068:0.003320:0.004192:0.007970:0.008016:0.008659:0.008001:0.004192:0.008965:0.007328:0.008001:0.005324:0.007787:0.003702:0.003702:0.004192:0.007787:0.007068:0.007068:0.008659:0.005324:0.007787:0.007068:0.007404:0.004192:0.008965:0.004788:0.004192:0.005186:0.008659:0.008001:0.004192:0.013171:0.008965:0.009010:0.008001:0.003702:0.004192
d.  The proportion of false negatives out of all predicted negative instances :@0.135704:0.282183:0.646547:0.282183:0.646547:0.269157:0.135704:0.269157:0.009010:0.003320:0.004192:0.006027:0.008016:0.008659:0.008001:0.004192:0.008995:0.005324:0.008965:0.008995:0.008965:0.005324:0.005186:0.003702:0.008965:0.008659:0.004192:0.008965:0.004788:0.004192:0.004788:0.007787:0.003702:0.006486:0.008001:0.004192:0.008659:0.008001:0.009010:0.007787:0.005186:0.003702:0.007328:0.008001:0.006486:0.004192:0.008965:0.008659:0.005186:0.004192:0.008965:0.004788:0.004192:0.007787:0.003702:0.003702:0.004192:0.008995:0.005324:0.008001:0.009010:0.003702:0.007068:0.005186:0.008001:0.009010:0.004192:0.008659:0.008001:0.009010:0.007787:0.005186:0.003702:0.007328:0.008001:0.004192:0.003702:0.008659:0.006486:0.005186:0.007787:0.008659:0.007068:0.008001:0.006486:0.004192
 :@0.087395:0.308646:0.091586:0.308646:0.091586:0.295620:0.087395:0.295620:0.004192
9.  Which of the  following is true about a confusion matrix?:@0.116185:0.308646:0.519484:0.308646:0.519484:0.295620:0.116185:0.295620:0.008246:0.003320:0.004192:0.005370:0.014288:0.008659:0.003702:0.007068:0.008659:0.004192:0.008965:0.004788:0.004192:0.005186:0.008659:0.008001:0.004192:0.004192:0.004788:0.008965:0.003702:0.003702:0.008965:0.011060:0.003702:0.008659:0.009010:0.004192:0.003702:0.006486:0.004192:0.005186:0.005324:0.008659:0.008001:0.004192:0.007787:0.008995:0.008965:0.008659:0.005186:0.004192:0.007787:0.004192:0.007068:0.008965:0.008659:0.004788:0.008659:0.006486:0.003702:0.008965:0.008659:0.004192:0.013171:0.007787:0.005186:0.005324:0.003702:0.007022:0.006853
a.  The confusion  matrix shows only the correct predictions of a model. :@0.135704:0.330664:0.623340:0.330664:0.623340:0.317638:0.135704:0.317638:0.007787:0.003320:0.004192:0.007251:0.008016:0.008659:0.008001:0.004192:0.007068:0.008965:0.008659:0.004788:0.008659:0.006486:0.003702:0.008965:0.008659:0.004192:0.004192:0.013171:0.007787:0.005186:0.005324:0.003702:0.007022:0.004192:0.006486:0.008659:0.008965:0.011060:0.006486:0.004192:0.008965:0.008659:0.003702:0.007404:0.004192:0.005186:0.008659:0.008001:0.004192:0.007068:0.008965:0.005324:0.005324:0.008001:0.007068:0.005186:0.004192:0.008995:0.005324:0.008001:0.009010:0.003702:0.007068:0.005186:0.003702:0.008965:0.008659:0.006486:0.004192:0.008965:0.004788:0.004192:0.007787:0.004192:0.013171:0.008965:0.009010:0.008001:0.003702:0.003320:0.004192
b.  The  diagonal  elements of a confusion  matrix represent  the false  positives  and false  negatives. :@0.135704:0.353627:0.819597:0.353627:0.819597:0.340601:0.135704:0.340601:0.008995:0.003320:0.004192:0.006043:0.008016:0.008659:0.008001:0.004192:0.004192:0.009010:0.003702:0.007787:0.009010:0.008965:0.008659:0.007787:0.003702:0.004192:0.004192:0.008001:0.003702:0.008001:0.013171:0.008001:0.008659:0.005186:0.006486:0.004192:0.008965:0.004788:0.004192:0.007787:0.004192:0.007068:0.008965:0.008659:0.004788:0.008659:0.006486:0.003702:0.008965:0.008659:0.004192:0.004192:0.013171:0.007787:0.005186:0.005324:0.003702:0.007022:0.004192:0.005324:0.008001:0.008995:0.005324:0.008001:0.006486:0.008001:0.008659:0.005186:0.004192:0.004192:0.005186:0.008659:0.008001:0.004192:0.004788:0.007787:0.003702:0.006486:0.008001:0.004192:0.004192:0.008995:0.008965:0.006486:0.003702:0.005186:0.003702:0.007328:0.008001:0.006486:0.004192:0.004192:0.007787:0.008659:0.009010:0.004192:0.004788:0.007787:0.003702:0.006486:0.008001:0.004192:0.004192:0.008659:0.008001:0.009010:0.007787:0.005186:0.003702:0.007328:0.008001:0.006486:0.003320:0.004192
c.  The confusion matrix  can be used to calculate accuracy, precision, recall, and F1 score. :@0.135704:0.376590:0.744652:0.376590:0.744652:0.363564:0.135704:0.363564:0.007068:0.003320:0.004192:0.007970:0.008016:0.008659:0.008001:0.004192:0.007068:0.008965:0.008659:0.004788:0.008659:0.006486:0.003702:0.008965:0.008659:0.004192:0.013171:0.007787:0.005186:0.005324:0.003702:0.007022:0.004192:0.004192:0.007068:0.007787:0.008659:0.004192:0.008995:0.008001:0.004192:0.008659:0.006486:0.008001:0.009010:0.004192:0.005186:0.008965:0.004192:0.007068:0.007787:0.003702:0.007068:0.008659:0.003702:0.007787:0.005186:0.008001:0.004192:0.007787:0.007068:0.007068:0.008659:0.005324:0.007787:0.007068:0.007404:0.003320:0.004192:0.008995:0.005324:0.008001:0.007068:0.003702:0.006486:0.003702:0.008965:0.008659:0.003320:0.004192:0.005324:0.008001:0.007068:0.007787:0.003702:0.003702:0.003320:0.004192:0.007787:0.008659:0.009010:0.004192:0.007465:0.008246:0.004192:0.006486:0.007068:0.008965:0.005324:0.008001:0.003320:0.004192
d.  The confusion matrix is used only for regression problems. :@0.135704:0.399553:0.555861:0.399553:0.555861:0.386527:0.135704:0.386527:0.009010:0.003320:0.004192:0.006027:0.008016:0.008659:0.008001:0.004192:0.007068:0.008965:0.008659:0.004788:0.008659:0.006486:0.003702:0.008965:0.008659:0.004192:0.013171:0.007787:0.005186:0.005324:0.003702:0.007022:0.004192:0.003702:0.006486:0.004192:0.008659:0.006486:0.008001:0.009010:0.004192:0.008965:0.008659:0.003702:0.007404:0.004192:0.004788:0.008965:0.005324:0.004192:0.005324:0.008001:0.009010:0.005324:0.008001:0.006486:0.006486:0.003702:0.008965:0.008659:0.004192:0.008995:0.005324:0.008965:0.008995:0.003702:0.008001:0.013171:0.006486:0.003320:0.004192
 :@0.087395:0.426015:0.091586:0.426015:0.091586:0.412990:0.087395:0.412990:0.004192
10.  Which of this is a classification use case example? :@0.107940:0.426015:0.474279:0.426015:0.474279:0.412990:0.107940:0.412990:0.008246:0.008246:0.003320:0.004192:0.005370:0.014288:0.008659:0.003702:0.007068:0.008659:0.004192:0.008965:0.004788:0.004192:0.005186:0.008659:0.003702:0.006486:0.004192:0.003702:0.006486:0.004192:0.007787:0.004192:0.007068:0.003702:0.007787:0.006486:0.006486:0.003702:0.004788:0.003702:0.007068:0.007787:0.005186:0.003702:0.008965:0.008659:0.004192:0.008659:0.006486:0.008001:0.004192:0.007068:0.007787:0.006486:0.008001:0.004192:0.008001:0.007022:0.007787:0.013171:0.008995:0.003702:0.008001:0.006853:0.004192
[CBSE Handbook]:@0.809609:0.426015:0.927984:0.426015:0.927984:0.412990:0.809609:0.412990:0.004620:0.009469:0.008766:0.008123:0.007741:0.004192:0.010862:0.007787:0.008659:0.009010:0.008995:0.008965:0.008965:0.007603:0.004620
a.  House  Price prediction :@0.135704:0.448033:0.319263:0.448033:0.319263:0.435008:0.135704:0.435008:0.007787:0.003320:0.004192:0.007251:0.010862:0.008965:0.008659:0.006486:0.008001:0.004192:0.004192:0.008567:0.005324:0.003702:0.007068:0.008001:0.004192:0.008995:0.005324:0.008001:0.009010:0.003702:0.007068:0.005186:0.003702:0.008965:0.008659:0.004192
 :@0.455495:0.448033:0.459687:0.448033:0.459687:0.435008:0.455495:0.435008:0.004192
b.  Credit  card fraud :@0.544728:0.448033:0.687871:0.448033:0.687871:0.435008:0.544728:0.435008:0.008995:0.003320:0.004192:0.004421:0.009469:0.005324:0.008001:0.009010:0.003702:0.005186:0.004192:0.004192:0.007068:0.007787:0.005324:0.009010:0.004192:0.004788:0.005324:0.007787:0.008659:0.009010:0.004192
c.  Salary  prediction :@0.135704:0.470996:0.279565:0.470996:0.279565:0.457970:0.135704:0.457970:0.007068:0.003320:0.004192:0.007970:0.008123:0.007787:0.003702:0.007787:0.005324:0.007404:0.004192:0.004192:0.008995:0.005324:0.008001:0.009010:0.003702:0.007068:0.005186:0.003702:0.008965:0.008659:0.004192
 :@0.455495:0.470996:0.459687:0.470996:0.459687:0.457970:0.455495:0.457970:0.004192
d.  None of these :@0.544728:0.470996:0.665383:0.470996:0.665383:0.457970:0.544728:0.457970:0.009010:0.003320:0.004192:0.004406:0.011443:0.008965:0.008659:0.008001:0.004192:0.008965:0.004788:0.004192:0.005186:0.008659:0.008001:0.006486:0.008001:0.004192
 :@0.087395:0.497459:0.091586:0.497459:0.091586:0.484433:0.087395:0.484433:0.004192
11.  A teacher's marks prediction system predicts the marks of a student as 75, but the actual marks obtained by the student :@0.107940:0.497459:0.932165:0.497459:0.932165:0.484433:0.107940:0.484433:0.008246:0.008246:0.003320:0.004192:0.005370:0.009867:0.003367:0.005186:0.008001:0.007787:0.007068:0.008659:0.008001:0.005324:0.003519:0.006486:0.003356:0.013171:0.007787:0.005324:0.007603:0.006486:0.003369:0.008995:0.005324:0.008001:0.009010:0.003702:0.007068:0.005186:0.003702:0.008965:0.008659:0.003356:0.006486:0.007404:0.006486:0.005186:0.008001:0.013171:0.003376:0.008995:0.005324:0.008001:0.009010:0.003702:0.007068:0.005186:0.006486:0.003361:0.005186:0.008659:0.008001:0.003362:0.013171:0.007787:0.005324:0.007603:0.006486:0.003366:0.008965:0.004788:0.003366:0.007787:0.003362:0.006486:0.005186:0.008659:0.009010:0.008001:0.008659:0.005186:0.003362:0.007787:0.006486:0.003367:0.008246:0.008246:0.003320:0.003366:0.008995:0.008659:0.005186:0.003361:0.005186:0.008659:0.008001:0.003362:0.007787:0.007068:0.005186:0.008659:0.007787:0.003702:0.003358:0.013171:0.007787:0.005324:0.007603:0.006486:0.003369:0.008965:0.008995:0.005186:0.007787:0.003702:0.008659:0.008001:0.009010:0.003358:0.008995:0.007404:0.003362:0.005186:0.008659:0.008001:0.003362:0.006486:0.005186:0.008659:0.009010:0.008001:0.008659:0.005186:0.004192
are 80. What is the absolute error in the prediction? :@0.137314:0.515978:0.488493:0.515978:0.488493:0.502952:0.137314:0.502952:0.007787:0.005324:0.008001:0.004192:0.008246:0.008246:0.003320:0.004192:0.014288:0.008659:0.007787:0.005186:0.004192:0.003702:0.006486:0.004192:0.005186:0.008659:0.008001:0.004192:0.007787:0.008995:0.006486:0.008965:0.003702:0.008659:0.005186:0.008001:0.004192:0.008001:0.005324:0.005324:0.008965:0.005324:0.004192:0.003702:0.008659:0.004192:0.005186:0.008659:0.008001:0.004192:0.008995:0.005324:0.008001:0.009010:0.003702:0.007068:0.005186:0.003702:0.008965:0.008659:0.006853:0.004192
[CBSE Handbook]:@0.809611:0.515978:0.927986:0.515978:0.927986:0.502952:0.809611:0.502952:0.004620:0.009469:0.008766:0.008123:0.007741:0.004192:0.010862:0.007787:0.008659:0.009010:0.008995:0.008965:0.008965:0.007603:0.004620
a.  5 :@0.135704:0.537996:0.170690:0.537996:0.170690:0.524970:0.135704:0.524970:0.007787:0.003320:0.004192:0.007251:0.008246:0.004192
 :@0.188849:0.537996:0.193040:0.537996:0.193040:0.524970:0.188849:0.524970:0.004192
 :@0.455495:0.537996:0.459687:0.537996:0.459687:0.524970:0.455495:0.524970:0.004192
b.  10 :@0.544728:0.537996:0.586338:0.537996:0.586338:0.524970:0.544728:0.524970:0.008995:0.003320:0.004192:0.004421:0.008246:0.008246:0.004192
c.  15   :@0.135704:0.560959:0.193040:0.560959:0.193040:0.547933:0.135704:0.547933:0.007068:0.003320:0.004192:0.007970:0.008246:0.008246:0.004192:0.009913:0.004192
 :@0.455495:0.560959:0.459687:0.560959:0.459687:0.547933:0.455495:0.547933:0.004192
d.  20                     :@0.544728:0.560959:0.670171:0.560959:0.670171:0.547933:0.544728:0.547933:0.009010:0.003320:0.004192:0.004406:0.008246:0.008246:0.004192:0.004192:0.004192:0.004192:0.004192:0.004192:0.004192:0.004192:0.004192:0.004192:0.004192:0.004192:0.004192:0.004192:0.004192:0.004192:0.004192:0.004192:0.004192:0.004192:0.004192
 :@0.087395:0.587421:0.091586:0.587421:0.091586:0.574395:0.087395:0.574395:0.004192
12.  How is the relationship between model performance and accuracy described? :@0.107940:0.587421:0.664218:0.587421:0.664218:0.574395:0.107940:0.574395:0.008246:0.008246:0.003320:0.004192:0.005370:0.010862:0.008965:0.011060:0.004192:0.003702:0.006486:0.004192:0.005186:0.008659:0.008001:0.004192:0.005324:0.008001:0.003702:0.007787:0.005186:0.003702:0.008965:0.008659:0.006486:0.008659:0.003702:0.008995:0.004192:0.008995:0.008001:0.005186:0.011060:0.008001:0.008001:0.008659:0.004192:0.013171:0.008965:0.009010:0.008001:0.003702:0.004192:0.008995:0.008001:0.005324:0.004788:0.008965:0.005324:0.013171:0.007787:0.008659:0.007068:0.008001:0.004192:0.007787:0.008659:0.009010:0.004192:0.007787:0.007068:0.007068:0.008659:0.005324:0.007787:0.007068:0.007404:0.004192:0.009010:0.008001:0.006486:0.007068:0.005324:0.003702:0.008995:0.008001:0.009010:0.006853:0.004192
[CBSE Handbook]:@0.809609:0.587421:0.927984:0.587421:0.927984:0.574395:0.809609:0.574395:0.004620:0.009469:0.008766:0.008123:0.007741:0.004192:0.010862:0.007787:0.008659:0.009010:0.008995:0.008965:0.008965:0.007603:0.004620
a.  Inversely proportional :@0.135704:0.609439:0.310176:0.609439:0.310176:0.596413:0.135704:0.596413:0.007787:0.003320:0.004192:0.007251:0.004069:0.008659:0.007328:0.008001:0.005324:0.006486:0.008001:0.003702:0.007404:0.004192:0.008995:0.005324:0.008965:0.008995:0.008965:0.005324:0.005186:0.003702:0.008965:0.008659:0.007787:0.003702:0.004192
 :@0.455495:0.609439:0.459687:0.609439:0.459687:0.596413:0.455495:0.596413:0.004192
b.  Not related :@0.544728:0.609439:0.646643:0.609439:0.646643:0.596413:0.544728:0.596413:0.008995:0.003320:0.004192:0.004421:0.011443:0.008965:0.005186:0.004192:0.005324:0.008001:0.003702:0.007787:0.005186:0.008001:0.009010:0.004192
c.  Directly proportional :@0.135704:0.632402:0.302313:0.632402:0.302313:0.619376:0.135704:0.619376:0.007068:0.003320:0.004192:0.007970:0.010724:0.003702:0.005324:0.008001:0.007068:0.005186:0.003702:0.007404:0.004192:0.008995:0.005324:0.008965:0.008995:0.008965:0.005324:0.005186:0.003702:0.008965:0.008659:0.007787:0.003702:0.004192
 :@0.455495:0.632402:0.459687:0.632402:0.459687:0.619376:0.455495:0.619376:0.004192
d.  Randomly fluctuating :@0.544728:0.632402:0.714290:0.632402:0.714290:0.619376:0.544728:0.619376:0.009010:0.003320:0.004192:0.004406:0.009148:0.007787:0.008659:0.009010:0.008965:0.013171:0.003702:0.007404:0.004192:0.004788:0.003702:0.008659:0.007068:0.005186:0.008659:0.007787:0.005186:0.003702:0.008659:0.009010:0.004192
B.  Fill in the blanks.:@0.087395:0.664513:0.241564:0.664513:0.241564:0.650065:0.087395:0.650065:0.010213:0.004075:0.004650:0.006831:0.008488:0.004413:0.004413:0.004413:0.004650:0.004413:0.009857:0.004650:0.006104:0.009841:0.008978:0.004650:0.010196:0.004413:0.008826:0.009857:0.008877:0.007287:0.004075
 :@0.087395:0.689815:0.091586:0.689815:0.091586:0.676789:0.087395:0.676789:0.004192
1. :@0.116185:0.689815:0.131942:0.689815:0.131942:0.676789:0.116185:0.676789:0.008246:0.003320:0.004192
……………………….:@0.137314:0.689815:0.241554:0.689815:0.241554:0.676789:0.137314:0.676789:0.011213:0.011213:0.011213:0.011213:0.011213:0.011213:0.011213:0.011213:0.011213:0.003320
 occurs when a model performs well on the training data but poorly on test data because it memorizes :@0.241539:0.689815:0.932155:0.689815:0.932155:0.676789:0.241539:0.676789:0.003948:0.008965:0.007068:0.007068:0.008659:0.005324:0.006486:0.003942:0.011060:0.008659:0.008001:0.008659:0.003939:0.007787:0.003944:0.013171:0.008965:0.009010:0.008001:0.003702:0.003953:0.008995:0.008001:0.005324:0.004788:0.008965:0.005324:0.013171:0.006486:0.003944:0.011060:0.008001:0.003702:0.003702:0.003947:0.008965:0.008659:0.003947:0.005186:0.008659:0.008001:0.003944:0.005186:0.005324:0.007787:0.003702:0.008659:0.003702:0.008659:0.009010:0.003939:0.009010:0.007787:0.005186:0.007787:0.003938:0.008995:0.008659:0.005186:0.003942:0.008995:0.008965:0.008965:0.005324:0.003702:0.007404:0.003941:0.008965:0.008659:0.003945:0.005186:0.008001:0.006486:0.005186:0.003947:0.009010:0.007787:0.005186:0.007787:0.003938:0.008995:0.008001:0.007068:0.007787:0.008659:0.006486:0.008001:0.003944:0.003702:0.005186:0.003948:0.013171:0.008001:0.013171:0.008965:0.005324:0.003702:0.006915:0.008001:0.006486:0.004192
the training data instead of generalizing.:@0.137314:0.709568:0.410290:0.709568:0.410290:0.696542:0.137314:0.696542:0.005186:0.008659:0.008001:0.004192:0.005186:0.005324:0.007787:0.003702:0.008659:0.003702:0.008659:0.009010:0.004192:0.009010:0.007787:0.005186:0.007787:0.004192:0.003702:0.008659:0.006486:0.005186:0.008001:0.007787:0.009010:0.004192:0.008965:0.004788:0.004192:0.009010:0.008001:0.008659:0.008001:0.005324:0.007787:0.003702:0.003702:0.006915:0.003702:0.008659:0.009010:0.003320
 :@0.087395:0.737195:0.091586:0.737195:0.091586:0.724169:0.087395:0.724169:0.004192
2. :@0.116185:0.737195:0.131942:0.737195:0.131942:0.724169:0.116185:0.724169:0.008246:0.003320:0.004192
……………………….:@0.137314:0.737195:0.241554:0.737195:0.241554:0.724169:0.137314:0.724169:0.011213:0.011213:0.011213:0.011213:0.011213:0.011213:0.011213:0.011213:0.011213:0.003320
 is prioritized over precision when false negatives are more costly than false positives.:@0.241539:0.737195:0.815470:0.737195:0.815470:0.724169:0.241539:0.724169:0.004192:0.003702:0.006486:0.004192:0.008995:0.005324:0.003702:0.008965:0.005324:0.003702:0.005186:0.003702:0.006915:0.008001:0.009010:0.004192:0.008965:0.007328:0.008001:0.005324:0.004192:0.008995:0.005324:0.008001:0.007068:0.003702:0.006486:0.003702:0.008965:0.008659:0.004192:0.011060:0.008659:0.008001:0.008659:0.004192:0.004788:0.007787:0.003702:0.006486:0.008001:0.004192:0.008659:0.008001:0.009010:0.007787:0.005186:0.003702:0.007328:0.008001:0.006486:0.004192:0.007787:0.005324:0.008001:0.004192:0.013171:0.008965:0.005324:0.008001:0.004192:0.007068:0.008965:0.006486:0.005186:0.003702:0.007404:0.004192:0.005186:0.008659:0.007787:0.008659:0.004192:0.004788:0.007787:0.003702:0.006486:0.008001:0.004192:0.008995:0.008965:0.006486:0.003702:0.005186:0.003702:0.007328:0.008001:0.006486:0.003320
 :@0.087395:0.763073:0.091586:0.763073:0.091586:0.750047:0.087395:0.750047:0.004192
3.  A Confusion Matrix is a :@0.116185:0.763073:0.300133:0.763073:0.300133:0.750047:0.116185:0.750047:0.008246:0.003320:0.004192:0.005370:0.009867:0.004920:0.009469:0.008965:0.008659:0.004788:0.008659:0.006486:0.003702:0.008965:0.008659:0.004923:0.013738:0.007787:0.005186:0.005324:0.003702:0.007022:0.004909:0.003702:0.006486:0.004927:0.007787:0.004192
……………………….:@0.300860:0.763073:0.405100:0.763073:0.405100:0.750047:0.300860:0.750047:0.011213:0.011213:0.011213:0.011213:0.011213:0.011213:0.011213:0.011213:0.011213:0.003320
 structure that helps in measuring the performance of an AI model using the :@0.405084:0.763073:0.932170:0.763073:0.932170:0.750047:0.405084:0.750047:0.004918:0.006486:0.005186:0.005324:0.008659:0.007068:0.005186:0.008659:0.005324:0.008001:0.004905:0.005186:0.008659:0.007787:0.005178:0.004918:0.008659:0.008001:0.003702:0.008995:0.006486:0.004923:0.003702:0.008659:0.004921:0.013171:0.008001:0.007787:0.006486:0.008659:0.005324:0.003702:0.008659:0.009010:0.004917:0.005186:0.008659:0.008001:0.004915:0.008995:0.008001:0.005324:0.004788:0.008965:0.005324:0.013171:0.007787:0.008659:0.007068:0.008001:0.004903:0.008965:0.004788:0.004918:0.007787:0.008659:0.004914:0.009867:0.004069:0.004921:0.013171:0.008965:0.009010:0.008001:0.003702:0.004923:0.008659:0.006486:0.003702:0.008659:0.009010:0.004923:0.005186:0.008659:0.008001:0.004192
test data.:@0.137314:0.782826:0.199454:0.782826:0.199454:0.769800:0.137314:0.769800:0.005186:0.008001:0.006486:0.005186:0.004192:0.009010:0.007787:0.005186:0.007787:0.003320
 :@0.087395:0.808703:0.091586:0.808703:0.091586:0.795677:0.087395:0.795677:0.004192
4.  The target variable in a confusion matrix has two values Positive and :@0.116185:0.808703:0.600575:0.808703:0.600575:0.795677:0.116185:0.795677:0.008246:0.003320:0.004192:0.005370:0.008016:0.008659:0.008001:0.004192:0.005186:0.007787:0.005324:0.009010:0.008001:0.005186:0.004192:0.007328:0.007787:0.005324:0.003702:0.007787:0.008995:0.003702:0.008001:0.004192:0.003702:0.008659:0.004192:0.007787:0.004192:0.007068:0.008965:0.008659:0.004788:0.008659:0.006486:0.003702:0.008965:0.008659:0.004192:0.013171:0.007787:0.005186:0.005324:0.003702:0.007022:0.004192:0.008659:0.007787:0.006486:0.004192:0.005186:0.011060:0.008965:0.004192:0.007328:0.007787:0.003702:0.008659:0.008001:0.006486:0.004192:0.007952:0.008965:0.006486:0.003702:0.005186:0.003702:0.007328:0.008001:0.004192:0.007787:0.008659:0.009010:0.004192
……………………….:@0.600576:0.808703:0.704816:0.808703:0.704816:0.795677:0.600576:0.795677:0.011213:0.011213:0.011213:0.011213:0.011213:0.011213:0.011213:0.011213:0.011213:0.003320
.:@0.704801:0.808703:0.708120:0.808703:0.708120:0.795677:0.704801:0.795677:0.003320
 :@0.087395:0.834580:0.091586:0.834580:0.091586:0.821554:0.087395:0.821554:0.004192
5.  The rows (x-axis) in the confusion matrix represent the :@0.116185:0.834580:0.507093:0.834580:0.507093:0.821554:0.116185:0.821554:0.008246:0.003320:0.004192:0.005370:0.008016:0.008659:0.008001:0.004192:0.005324:0.008965:0.011060:0.006486:0.004192:0.004620:0.007022:0.006119:0.007787:0.007022:0.003702:0.006486:0.004620:0.004192:0.003702:0.008659:0.004192:0.005186:0.008659:0.008001:0.004192:0.007068:0.008965:0.008659:0.004788:0.008659:0.006486:0.003702:0.008965:0.008659:0.004192:0.013171:0.007787:0.005186:0.005324:0.003702:0.007022:0.004192:0.005324:0.008001:0.008995:0.005324:0.008001:0.006486:0.008001:0.008659:0.005186:0.004192:0.005186:0.008659:0.008001:0.004192
……………………….:@0.507048:0.834580:0.611288:0.834580:0.611288:0.821554:0.507048:0.821554:0.011213:0.011213:0.011213:0.011213:0.011213:0.011213:0.011213:0.011213:0.011213:0.003320
 values of the target variable.:@0.611273:0.834580:0.806229:0.834580:0.806229:0.821554:0.611273:0.821554:0.004192:0.007328:0.007787:0.003702:0.008659:0.008001:0.006486:0.004192:0.008965:0.004788:0.004192:0.005186:0.008659:0.008001:0.004192:0.005186:0.007787:0.005324:0.009010:0.008001:0.005186:0.004192:0.007328:0.007787:0.005324:0.003702:0.007787:0.008995:0.003702:0.008001:0.003320
 :@0.087395:0.860458:0.091586:0.860458:0.091586:0.847432:0.087395:0.847432:0.004192
6.  The F1 score is a number between 0 and 1 and is the harmonic mean of :@0.116185:0.860458:0.623433:0.860458:0.623433:0.847432:0.116185:0.847432:0.008246:0.003320:0.004192:0.005370:0.008016:0.008659:0.008001:0.004192:0.007465:0.008246:0.004192:0.006486:0.007068:0.008965:0.005324:0.008001:0.004192:0.003702:0.006486:0.004192:0.007787:0.004192:0.008659:0.008659:0.013171:0.008995:0.008001:0.005324:0.004192:0.008995:0.008001:0.005186:0.011060:0.008001:0.008001:0.008659:0.004192:0.008246:0.004192:0.007787:0.008659:0.009010:0.004192:0.008246:0.004192:0.007787:0.008659:0.009010:0.004192:0.003702:0.006486:0.004192:0.005186:0.008659:0.008001:0.004192:0.008659:0.007787:0.005324:0.013171:0.008965:0.008659:0.003702:0.007068:0.004192:0.013171:0.008001:0.007787:0.008659:0.004192:0.008965:0.004788:0.004192
……………………….:@0.623389:0.860458:0.727629:0.860458:0.727629:0.847432:0.623389:0.847432:0.011213:0.011213:0.011213:0.011213:0.011213:0.011213:0.011213:0.011213:0.011213:0.003320
 and recall.:@0.727613:0.860458:0.800355:0.860458:0.800355:0.847432:0.727613:0.847432:0.004192:0.007787:0.008659:0.009010:0.004192:0.005324:0.008001:0.007068:0.007787:0.003702:0.003702:0.003320
 :@0.087395:0.886335:0.091586:0.886335:0.091586:0.873309:0.087395:0.873309:0.004192
7.  The  ideal  scenario  is  called :@0.116185:0.886335:0.333166:0.886335:0.333166:0.873309:0.116185:0.873309:0.008246:0.003320:0.004192:0.005370:0.008016:0.008659:0.008001:0.004192:0.003139:0.003702:0.009010:0.008001:0.007787:0.003702:0.004192:0.003142:0.006486:0.007068:0.008001:0.008659:0.007787:0.005324:0.003702:0.008965:0.004192:0.003138:0.003702:0.006486:0.004192:0.003151:0.007068:0.007787:0.003702:0.003702:0.008001:0.009010:0.004192
……………………….:@0.336310:0.886335:0.440550:0.886335:0.440550:0.873309:0.336310:0.873309:0.011213:0.011213:0.011213:0.011213:0.011213:0.011213:0.011213:0.011213:0.011213:0.003320
,  where  the  model  strikes  the  right  balance  between  complexity  and :@0.440534:0.886335:0.932172:0.886335:0.932172:0.873309:0.440534:0.873309:0.003320:0.004192:0.003139:0.011060:0.008659:0.008001:0.005324:0.008001:0.004192:0.003130:0.005186:0.008659:0.008001:0.004192:0.003139:0.013171:0.008965:0.009010:0.008001:0.003702:0.004192:0.003147:0.006486:0.005186:0.005324:0.003702:0.007603:0.008001:0.006486:0.004192:0.003148:0.005186:0.008659:0.008001:0.004192:0.003138:0.005324:0.003702:0.009010:0.008659:0.005186:0.004192:0.003136:0.008995:0.007787:0.003702:0.007787:0.008659:0.007068:0.008001:0.004192:0.003133:0.008995:0.008001:0.005186:0.011060:0.008001:0.008001:0.008659:0.004192:0.003132:0.007068:0.008965:0.013171:0.008995:0.003702:0.008001:0.007022:0.003702:0.005186:0.007404:0.004192:0.003144:0.007787:0.008659:0.009010:0.004192
simplicity, performing well on both training and test data.:@0.137314:0.906088:0.524550:0.906088:0.524550:0.893062:0.137314:0.893062:0.006486:0.003702:0.013171:0.008995:0.003702:0.003702:0.007068:0.003702:0.005186:0.007404:0.003320:0.004192:0.008995:0.008001:0.005324:0.004788:0.008965:0.005324:0.013171:0.003702:0.008659:0.009010:0.004192:0.011060:0.008001:0.003702:0.003702:0.004192:0.008965:0.008659:0.004192:0.008995:0.008965:0.005186:0.008659:0.004192:0.005186:0.005324:0.007787:0.003702:0.008659:0.003702:0.008659:0.009010:0.004192:0.007787:0.008659:0.009010:0.004192:0.005186:0.008001:0.006486:0.005186:0.004192:0.009010:0.007787:0.005186:0.007787:0.003320