T:@0.180169:0.948923:0.188607:0.948923:0.188607:0.935211:0.180169:0.935211:0.008438
ouchpad Artificial Intelligence (Ver. 3.0):@0.187317:0.948923:0.463822:0.948083:0.463822:0.934372:0.187317:0.935211:0.009436:0.009114:0.007440:0.009114:0.009469:0.008196:0.009485:0.004412:0.010386:0.005604:0.005459:0.003897:0.004469:0.004469:0.007440:0.003897:0.008196:0.003897:0.004412:0.004283:0.009114:0.005459:0.008422:0.003897:0.003897:0.003897:0.009485:0.008422:0.009114:0.007440:0.008422:0.004412:0.004863:0.008952:0.008422:0.005604:0.003494:0.004412:0.008680:0.003494:0.008665:-0.373357
-X:@0.463821:0.948260:0.480037:0.948926:0.480037:0.935215:0.463821:0.934548:0.006715:-0.386033
240:@0.118726:0.949910:0.144765:0.949910:0.144765:0.936198:0.118726:0.936198:0.008680:0.008680:0.008680
Exercise:@0.431781:0.087155:0.554538:0.087155:0.554538:0.048733:0.431781:0.048733:0.016538:0.015910:0.016747:0.015659:0.016705:0.008206:0.016245:0.016747
Solved Questions:@0.401925:0.126714:0.610077:0.126714:0.610077:0.102180:0.401925:0.102180:0.015742:0.014918:0.006081:0.013318:0.013424:0.015639:0.007214:0.020045:0.014480:0.013527:0.013501:0.011285:0.006081:0.014918:0.014480:0.013501
SECTION A :@0.340720:0.157645:0.436780:0.157645:0.436780:0.142497:0.340720:0.142497:0.009937:0.009424:0.011053:0.010380:0.005615:0.013427:0.013994:0.004889:0.012452:0.004889
(Objective Type Questions):@0.436777:0.157461:0.645641:0.157461:0.645641:0.142378:0.436777:0.142378:0.005349:0.013356:0.010415:0.004287:0.009264:0.008184:0.006005:0.004287:0.008485:0.009264:0.004853:0.008295:0.008573:0.010415:0.009264:0.004853:0.013356:0.010026:0.009264:0.007510:0.006005:0.004287:0.010380:0.010026:0.007510:0.005349
A.  Tick ( ) the correct option.:@0.072888:0.202995:0.306451:0.202995:0.306451:0.188548:0.072888:0.188548:0.011345:0.004075:0.004650:0.005698:0.009333:0.004413:0.007947:0.008877:0.004650:0.005614:0.014176:0.005614:0.004650:0.006104:0.009841:0.008978:0.004650:0.007947:0.010094:0.006256:0.006126:0.008978:0.007947:0.006104:0.004650:0.010094:0.010196:0.006104:0.004428:0.010094:0.009857:0.004075
 :@0.072888:0.227938:0.077080:0.227938:0.077080:0.214912:0.072888:0.214912:0.004192
1.  Why is it essential  to evaluate a machine  learning model using evaluation techniques such as  train-test split?:@0.101679:0.227938:0.864432:0.227938:0.864432:0.214912:0.101679:0.214912:0.008246:0.003320:0.004192:0.005370:0.014288:0.008659:0.007404:0.004192:0.003702:0.006486:0.004192:0.003702:0.005186:0.004192:0.008001:0.006486:0.006486:0.008001:0.008659:0.005186:0.003702:0.007787:0.003702:0.004192:0.004192:0.005186:0.008965:0.004192:0.008001:0.007328:0.007787:0.003702:0.008659:0.007787:0.005186:0.008001:0.004192:0.007787:0.004192:0.013171:0.007787:0.007068:0.008659:0.003702:0.008659:0.008001:0.004192:0.004192:0.003702:0.008001:0.007787:0.005324:0.008659:0.003702:0.008659:0.009010:0.004192:0.013171:0.008965:0.009010:0.008001:0.003702:0.004192:0.008659:0.006486:0.003702:0.008659:0.009010:0.004192:0.008001:0.007328:0.007787:0.003702:0.008659:0.007787:0.005186:0.003702:0.008965:0.008659:0.004192:0.005186:0.008001:0.007068:0.008659:0.008659:0.003702:0.009010:0.008659:0.008001:0.006486:0.004192:0.006486:0.008659:0.007068:0.008659:0.004192:0.007787:0.006486:0.004192:0.004192:0.005186:0.005324:0.007787:0.003702:0.008659:0.006119:0.005186:0.008001:0.006486:0.005186:0.004192:0.006486:0.008995:0.003702:0.003702:0.005186:0.006853
a.  To increase  the complexity of the model :@0.121197:0.249956:0.421301:0.249956:0.421301:0.236930:0.121197:0.236930:0.007787:0.003320:0.004192:0.007251:0.006522:0.008965:0.004192:0.003702:0.008659:0.007068:0.005324:0.008001:0.007787:0.006486:0.008001:0.004192:0.004192:0.005186:0.008659:0.008001:0.004192:0.007068:0.008965:0.013171:0.008995:0.003702:0.008001:0.007022:0.003702:0.005186:0.007404:0.004192:0.008965:0.004788:0.004192:0.005186:0.008659:0.008001:0.004192:0.013171:0.008965:0.009010:0.008001:0.003702:0.004192
b.  To reduce the size of the training dataset :@0.121197:0.275474:0.422846:0.275474:0.422846:0.262448:0.121197:0.262448:0.008995:0.003320:0.004192:0.006043:0.006522:0.008965:0.004192:0.005324:0.008001:0.009010:0.008659:0.007068:0.008001:0.004192:0.005186:0.008659:0.008001:0.004192:0.006486:0.003702:0.006915:0.008001:0.004192:0.008965:0.004788:0.004192:0.005186:0.008659:0.008001:0.004192:0.005186:0.005324:0.007787:0.003702:0.008659:0.003702:0.008659:0.009010:0.004192:0.009010:0.007787:0.005186:0.007787:0.006486:0.008001:0.005186:0.004192
c.  To eliminate the need for testing data :@0.121197:0.300991:0.401077:0.300991:0.401077:0.287965:0.121197:0.287965:0.007068:0.003320:0.004192:0.007970:0.006522:0.008965:0.004192:0.008001:0.003702:0.003702:0.013171:0.003702:0.008659:0.007787:0.005186:0.008001:0.004192:0.005186:0.008659:0.008001:0.004192:0.008659:0.008001:0.008001:0.009010:0.004192:0.004788:0.008965:0.005324:0.004192:0.005186:0.008001:0.006486:0.005186:0.003702:0.008659:0.009010:0.004192:0.009010:0.007787:0.005186:0.007787:0.004192
d.  To assess how well the model performs on unseen data :@0.121197:0.326509:0.519636:0.326509:0.519636:0.313483:0.121197:0.313483:0.009010:0.003320:0.004192:0.006027:0.006522:0.008965:0.004192:0.007787:0.006486:0.006486:0.008001:0.006486:0.006486:0.004192:0.008659:0.008965:0.011060:0.004192:0.011060:0.008001:0.003702:0.003702:0.004192:0.005186:0.008659:0.008001:0.004192:0.013171:0.008965:0.009010:0.008001:0.003702:0.004192:0.008995:0.008001:0.005324:0.004788:0.008965:0.005324:0.013171:0.006486:0.004192:0.008965:0.008659:0.004192:0.008659:0.008659:0.006486:0.008001:0.008001:0.008659:0.004192:0.009010:0.007787:0.005186:0.007787:0.004192
 :@0.072888:0.352971:0.077080:0.352971:0.077080:0.339946:0.072888:0.339946:0.004192
2.  Which of the following describes an overfitting scenario in model evaluation?:@0.101679:0.352971:0.642444:0.352971:0.642444:0.339946:0.101679:0.339946:0.008246:0.003320:0.004192:0.005370:0.014288:0.008659:0.003702:0.007068:0.008659:0.004192:0.008965:0.004788:0.004192:0.005186:0.008659:0.008001:0.004192:0.004788:0.008965:0.003702:0.003702:0.008965:0.011060:0.003702:0.008659:0.009010:0.004192:0.009010:0.008001:0.006486:0.007068:0.005324:0.003702:0.008995:0.008001:0.006486:0.004192:0.007787:0.008659:0.004192:0.008965:0.007328:0.008001:0.005324:0.004788:0.003702:0.005186:0.005186:0.003702:0.008659:0.009010:0.004192:0.006486:0.007068:0.008001:0.008659:0.007787:0.005324:0.003702:0.008965:0.004192:0.003702:0.008659:0.004192:0.013171:0.008965:0.009010:0.008001:0.003702:0.004192:0.008001:0.007328:0.007787:0.003702:0.008659:0.007787:0.005186:0.003702:0.008965:0.008659:0.006853
a.  The model performs poorly on both training and test data. :@0.121197:0.374990:0.542456:0.374990:0.542456:0.361964:0.121197:0.361964:0.007787:0.003320:0.004192:0.007251:0.008016:0.008659:0.008001:0.004192:0.013171:0.008965:0.009010:0.008001:0.003702:0.004192:0.008995:0.008001:0.005324:0.004788:0.008965:0.005324:0.013171:0.006486:0.004192:0.008995:0.008965:0.008965:0.005324:0.003702:0.007404:0.004192:0.008965:0.008659:0.004192:0.008995:0.008965:0.005186:0.008659:0.004192:0.005186:0.005324:0.007787:0.003702:0.008659:0.003702:0.008659:0.009010:0.004192:0.007787:0.008659:0.009010:0.004192:0.005186:0.008001:0.006486:0.005186:0.004192:0.009010:0.007787:0.005186:0.007787:0.003320:0.004192
b.  The model performs well on both training and test data. :@0.121197:0.400507:0.525567:0.400507:0.525567:0.387481:0.121197:0.387481:0.008995:0.003320:0.004192:0.006043:0.008016:0.008659:0.008001:0.004192:0.013171:0.008965:0.009010:0.008001:0.003702:0.004192:0.008995:0.008001:0.005324:0.004788:0.008965:0.005324:0.013171:0.006486:0.004192:0.011060:0.008001:0.003702:0.003702:0.004192:0.008965:0.008659:0.004192:0.008995:0.008965:0.005186:0.008659:0.004192:0.005186:0.005324:0.007787:0.003702:0.008659:0.003702:0.008659:0.009010:0.004192:0.007787:0.008659:0.009010:0.004192:0.005186:0.008001:0.006486:0.005186:0.004192:0.009010:0.007787:0.005186:0.007787:0.003320:0.004192
c.  The model performs well on training data but poorly on test data. :@0.121197:0.426025:0.590277:0.426025:0.590277:0.412999:0.121197:0.412999:0.007068:0.003320:0.004192:0.007970:0.008016:0.008659:0.008001:0.004192:0.013171:0.008965:0.009010:0.008001:0.003702:0.004192:0.008995:0.008001:0.005324:0.004788:0.008965:0.005324:0.013171:0.006486:0.004192:0.011060:0.008001:0.003702:0.003702:0.004192:0.008965:0.008659:0.004192:0.005186:0.005324:0.007787:0.003702:0.008659:0.003702:0.008659:0.009010:0.004192:0.009010:0.007787:0.005186:0.007787:0.004192:0.008995:0.008659:0.005186:0.004192:0.008995:0.008965:0.008965:0.005324:0.003702:0.007404:0.004192:0.008965:0.008659:0.004192:0.005186:0.008001:0.006486:0.005186:0.004192:0.009010:0.007787:0.005186:0.007787:0.003320:0.004192
d.  The model performs poorly only on test data but memorizes random noise from training data. :@0.121197:0.451542:0.782205:0.451542:0.782205:0.438517:0.121197:0.438517:0.009010:0.003320:0.004192:0.006027:0.008016:0.008659:0.008001:0.004192:0.013171:0.008965:0.009010:0.008001:0.003702:0.004192:0.008995:0.008001:0.005324:0.004788:0.008965:0.005324:0.013171:0.006486:0.004192:0.008995:0.008965:0.008965:0.005324:0.003702:0.007404:0.004192:0.008965:0.008659:0.003702:0.007404:0.004192:0.008965:0.008659:0.004192:0.005186:0.008001:0.006486:0.005186:0.004192:0.009010:0.007787:0.005186:0.007787:0.004192:0.008995:0.008659:0.005186:0.004192:0.013171:0.008001:0.013171:0.008965:0.005324:0.003702:0.006915:0.008001:0.006486:0.004192:0.005324:0.007787:0.008659:0.009010:0.008965:0.013171:0.004192:0.008659:0.008965:0.003702:0.006486:0.008001:0.004192:0.004788:0.005324:0.008965:0.013171:0.004192:0.005186:0.005324:0.007787:0.003702:0.008659:0.003702:0.008659:0.009010:0.004192:0.009010:0.007787:0.005186:0.007787:0.003320:0.004192
 :@0.072888:0.478622:0.077080:0.478622:0.077080:0.465596:0.072888:0.465596:0.004192
3.  What does a \perfect fit\ represent in model evaluation?:@0.101679:0.478622:0.501352:0.478622:0.501352:0.465596:0.101679:0.465596:0.008246:0.003320:0.004192:0.005370:0.014288:0.008659:0.007787:0.005186:0.004192:0.009010:0.008965:0.008001:0.006486:0.004192:0.007787:0.004192:0.005997:0.008995:0.008001:0.005324:0.004788:0.008001:0.007068:0.005186:0.004192:0.004788:0.003702:0.005186:0.005997:0.004192:0.005324:0.008001:0.008995:0.005324:0.008001:0.006486:0.008001:0.008659:0.005186:0.004192:0.003702:0.008659:0.004192:0.013171:0.008965:0.009010:0.008001:0.003702:0.004192:0.008001:0.007328:0.007787:0.003702:0.008659:0.007787:0.005186:0.003702:0.008965:0.008659:0.006853
a.  The ideal balance between complexity and generalisation :@0.121197:0.500640:0.533506:0.500640:0.533506:0.487614:0.121197:0.487614:0.007787:0.003320:0.004192:0.007251:0.008016:0.008659:0.008001:0.004192:0.003702:0.009010:0.008001:0.007787:0.003702:0.004192:0.008995:0.007787:0.003702:0.007787:0.008659:0.007068:0.008001:0.004192:0.008995:0.008001:0.005186:0.011060:0.008001:0.008001:0.008659:0.004192:0.007068:0.008965:0.013171:0.008995:0.003702:0.008001:0.007022:0.003702:0.005186:0.007404:0.004192:0.007787:0.008659:0.009010:0.004192:0.009010:0.008001:0.008659:0.008001:0.005324:0.007787:0.003702:0.003702:0.006486:0.007787:0.005186:0.003702:0.008965:0.008659:0.004192
b.  High bias and low variance :@0.121197:0.526158:0.328744:0.526158:0.328744:0.513132:0.121197:0.513132:0.008995:0.003320:0.004192:0.006043:0.010862:0.003702:0.009010:0.008659:0.004192:0.008995:0.003702:0.007787:0.006486:0.004192:0.007787:0.008659:0.009010:0.004192:0.003702:0.008965:0.011060:0.004192:0.007328:0.007787:0.005324:0.003702:0.007787:0.008659:0.007068:0.008001:0.004192
c.  Low bias and high variance :@0.121197:0.551676:0.330044:0.551676:0.330044:0.538650:0.121197:0.538650:0.007068:0.003320:0.004192:0.007970:0.007205:0.008965:0.011060:0.004192:0.008995:0.003702:0.007787:0.006486:0.004192:0.007787:0.008659:0.009010:0.004192:0.008659:0.003702:0.009010:0.008659:0.004192:0.007328:0.007787:0.005324:0.003702:0.007787:0.008659:0.007068:0.008001:0.004192
d.  Overfitting the training data :@0.121197:0.577193:0.336576:0.577193:0.336576:0.564167:0.121197:0.564167:0.009010:0.003320:0.004192:0.006027:0.011535:0.007328:0.008001:0.005324:0.004788:0.003702:0.005186:0.005186:0.003702:0.008659:0.009010:0.004192:0.005186:0.008659:0.008001:0.004192:0.005186:0.005324:0.007787:0.003702:0.008659:0.003702:0.008659:0.009010:0.004192:0.009010:0.007787:0.005186:0.007787:0.004192
 :@0.072888:0.604273:0.077080:0.604273:0.077080:0.591247:0.072888:0.591247:0.004192
4.  Which metric measures how many positive predictions made by the model are actually correct?:@0.101679:0.604273:0.764461:0.604273:0.764461:0.591247:0.101679:0.591247:0.008246:0.003320:0.004192:0.005370:0.014288:0.008659:0.003702:0.007068:0.008659:0.004192:0.013171:0.008001:0.005186:0.005324:0.003702:0.007068:0.004192:0.013171:0.008001:0.007787:0.006486:0.008659:0.005324:0.008001:0.006486:0.004192:0.008659:0.008965:0.011060:0.004192:0.013171:0.007787:0.008659:0.007404:0.004192:0.008995:0.008965:0.006486:0.003702:0.005186:0.003702:0.007328:0.008001:0.004192:0.008995:0.005324:0.008001:0.009010:0.003702:0.007068:0.005186:0.003702:0.008965:0.008659:0.006486:0.004192:0.013171:0.007787:0.009010:0.008001:0.004192:0.008995:0.007404:0.004192:0.005186:0.008659:0.008001:0.004192:0.013171:0.008965:0.009010:0.008001:0.003702:0.004192:0.007787:0.005324:0.008001:0.004192:0.007787:0.007068:0.005186:0.008659:0.007787:0.003702:0.003702:0.007404:0.004192:0.007068:0.008965:0.005324:0.005324:0.008001:0.007068:0.005186:0.006853
a. :@0.121197:0.626908:0.136495:0.626908:0.136495:0.613882:0.121197:0.613882:0.007787:0.003320:0.004192
Recall :@0.143742:0.626908:0.186894:0.626908:0.186894:0.613882:0.143742:0.613882:0.008701:0.008001:0.007068:0.007787:0.003702:0.003702:0.004192
 :@0.440989:0.626908:0.445181:0.626908:0.445181:0.613882:0.440989:0.613882:0.004192
b.  Precision :@0.530222:0.626908:0.615813:0.626908:0.615813:0.613882:0.530222:0.613882:0.008995:0.003320:0.004192:0.004421:0.008567:0.005324:0.008001:0.007068:0.003702:0.006486:0.003702:0.008965:0.008659:0.004192
c.  Accuracy :@0.121197:0.653043:0.208181:0.653043:0.208181:0.640017:0.121197:0.640017:0.007068:0.003320:0.004192:0.007970:0.009867:0.007068:0.007068:0.008659:0.005324:0.007787:0.007068:0.007404:0.004192
 :@0.440989:0.653043:0.445181:0.653043:0.445181:0.640017:0.440989:0.640017:0.004192
d.  F1-Score :@0.530222:0.653043:0.614651:0.653043:0.614651:0.640017:0.530222:0.640017:0.009010:0.003320:0.004192:0.004406:0.007465:0.008246:0.006119:0.008123:0.007068:0.008965:0.005324:0.008001:0.004192
 :@0.072888:0.680123:0.077080:0.680123:0.077080:0.667097:0.072888:0.667097:0.004192
5.  Which term refers to the actual value being positive, but the model predicting it as negative?:@0.101679:0.680123:0.747250:0.680123:0.747250:0.667097:0.101679:0.667097:0.008246:0.003320:0.004192:0.005370:0.014288:0.008659:0.003702:0.007068:0.008659:0.004192:0.005186:0.008001:0.005324:0.013171:0.004192:0.005324:0.008001:0.004788:0.008001:0.005324:0.006486:0.004192:0.005186:0.008965:0.004192:0.005186:0.008659:0.008001:0.004192:0.007787:0.007068:0.005186:0.008659:0.007787:0.003702:0.004192:0.007328:0.007787:0.003702:0.008659:0.008001:0.004192:0.008995:0.008001:0.003702:0.008659:0.009010:0.004192:0.008995:0.008965:0.006486:0.003702:0.005186:0.003702:0.007328:0.008001:0.003320:0.004192:0.008995:0.008659:0.005186:0.004192:0.005186:0.008659:0.008001:0.004192:0.013171:0.008965:0.009010:0.008001:0.003702:0.004192:0.008995:0.005324:0.008001:0.009010:0.003702:0.007068:0.005186:0.003702:0.008659:0.009010:0.004192:0.003702:0.005186:0.004192:0.007787:0.006486:0.004192:0.008659:0.008001:0.009010:0.007787:0.005186:0.003702:0.007328:0.008001:0.006853
a.  True Positive :@0.121197:0.702759:0.232159:0.702759:0.232159:0.689733:0.121197:0.689733:0.007787:0.003320:0.004192:0.007251:0.006685:0.005324:0.008659:0.008001:0.004192:0.007992:0.008965:0.006486:0.003702:0.005186:0.003702:0.007328:0.008001:0.004192
 :@0.440989:0.702759:0.445181:0.702759:0.445181:0.689733:0.440989:0.689733:0.004192
b.  False Positive :@0.530222:0.702759:0.643827:0.702759:0.643827:0.689733:0.530222:0.689733:0.008995:0.003320:0.004192:0.004421:0.006947:0.007787:0.003702:0.006486:0.008001:0.004192:0.008002:0.008965:0.006486:0.003702:0.005186:0.003702:0.007328:0.008001:0.004192
c.  False Negative :@0.121197:0.728893:0.245510:0.728893:0.245510:0.715868:0.121197:0.715868:0.007068:0.003320:0.004192:0.007970:0.006947:0.007787:0.003702:0.006486:0.008001:0.004192:0.011443:0.008001:0.009010:0.007787:0.005186:0.003702:0.007328:0.008001:0.004192
 :@0.440989:0.728893:0.445181:0.728893:0.445181:0.715868:0.440989:0.715868:0.004192
d.  True Negative :@0.530222:0.728893:0.648658:0.728893:0.648658:0.715868:0.530222:0.715868:0.009010:0.003320:0.004192:0.004406:0.006685:0.005324:0.008659:0.008001:0.004192:0.011443:0.008001:0.009010:0.007787:0.005186:0.003702:0.007328:0.008001:0.004192
 :@0.072888:0.755973:0.077080:0.755973:0.077080:0.742947:0.072888:0.742947:0.004192
6.  What is a False Positive (FP)?:@0.101679:0.755973:0.314076:0.755973:0.314076:0.742947:0.101679:0.742947:0.008246:0.003320:0.004192:0.005372:0.014288:0.008659:0.007787:0.005186:0.004192:0.003702:0.006486:0.004192:0.007787:0.004192:0.006942:0.007787:0.003702:0.006486:0.008001:0.004192:0.008002:0.008965:0.006486:0.003702:0.005186:0.003702:0.007328:0.008001:0.004192:0.004620:0.007465:0.008567:0.004620:0.006853
a.  When the model incorrectly predicts a positive value when the actual value is negative :@0.121197:0.777991:0.728279:0.777991:0.728279:0.764965:0.121197:0.764965:0.007787:0.003320:0.004192:0.007251:0.014288:0.008659:0.008001:0.008659:0.004192:0.005186:0.008659:0.008001:0.004192:0.013171:0.008965:0.009010:0.008001:0.003702:0.004192:0.003702:0.008659:0.007068:0.008965:0.005324:0.005324:0.008001:0.007068:0.005186:0.003702:0.007404:0.004192:0.008995:0.005324:0.008001:0.009010:0.003702:0.007068:0.005186:0.006486:0.004192:0.007787:0.004192:0.008995:0.008965:0.006486:0.003702:0.005186:0.003702:0.007328:0.008001:0.004192:0.007328:0.007787:0.003702:0.008659:0.008001:0.004192:0.011060:0.008659:0.008001:0.008659:0.004192:0.005186:0.008659:0.008001:0.004192:0.007787:0.007068:0.005186:0.008659:0.007787:0.003702:0.004192:0.007328:0.007787:0.003702:0.008659:0.008001:0.004192:0.003702:0.006486:0.004192:0.008659:0.008001:0.009010:0.007787:0.005186:0.003702:0.007328:0.008001:0.004192
b.  When the model correctly predicts a positive value :@0.121197:0.803509:0.489020:0.803509:0.489020:0.790483:0.121197:0.790483:0.008995:0.003320:0.004192:0.006043:0.014288:0.008659:0.008001:0.008659:0.004192:0.005186:0.008659:0.008001:0.004192:0.013171:0.008965:0.009010:0.008001:0.003702:0.004192:0.007068:0.008965:0.005324:0.005324:0.008001:0.007068:0.005186:0.003702:0.007404:0.004192:0.008995:0.005324:0.008001:0.009010:0.003702:0.007068:0.005186:0.006486:0.004192:0.007787:0.004192:0.008995:0.008965:0.006486:0.003702:0.005186:0.003702:0.007328:0.008001:0.004192:0.007328:0.007787:0.003702:0.008659:0.008001:0.004192
c.  When the model incorrectly predicts a negative value when the actual value is positive :@0.121197:0.829027:0.728279:0.829027:0.728279:0.816001:0.121197:0.816001:0.007068:0.003320:0.004192:0.007970:0.014288:0.008659:0.008001:0.008659:0.004192:0.005186:0.008659:0.008001:0.004192:0.013171:0.008965:0.009010:0.008001:0.003702:0.004192:0.003702:0.008659:0.007068:0.008965:0.005324:0.005324:0.008001:0.007068:0.005186:0.003702:0.007404:0.004192:0.008995:0.005324:0.008001:0.009010:0.003702:0.007068:0.005186:0.006486:0.004192:0.007787:0.004192:0.008659:0.008001:0.009010:0.007787:0.005186:0.003702:0.007328:0.008001:0.004192:0.007328:0.007787:0.003702:0.008659:0.008001:0.004192:0.011060:0.008659:0.008001:0.008659:0.004192:0.005186:0.008659:0.008001:0.004192:0.007787:0.007068:0.005186:0.008659:0.007787:0.003702:0.004192:0.007328:0.007787:0.003702:0.008659:0.008001:0.004192:0.003702:0.006486:0.004192:0.008995:0.008965:0.006486:0.003702:0.005186:0.003702:0.007328:0.008001:0.004192
d.  When the model correctly predicts a negative value :@0.121197:0.854544:0.494329:0.854544:0.494329:0.841518:0.121197:0.841518:0.009010:0.003320:0.004192:0.006027:0.014288:0.008659:0.008001:0.008659:0.004192:0.005186:0.008659:0.008001:0.004192:0.013171:0.008965:0.009010:0.008001:0.003702:0.004192:0.007068:0.008965:0.005324:0.005324:0.008001:0.007068:0.005186:0.003702:0.007404:0.004192:0.008995:0.005324:0.008001:0.009010:0.003702:0.007068:0.005186:0.006486:0.004192:0.007787:0.004192:0.008659:0.008001:0.009010:0.007787:0.005186:0.003702:0.007328:0.008001:0.004192:0.007328:0.007787:0.003702:0.008659:0.008001:0.004192
uiz:@0.125414:0.176691:0.148544:0.176691:0.148544:0.162232:0.125414:0.162232:0.010229:0.004802:0.008099